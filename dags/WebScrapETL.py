#Import All Necesary Module for Pyhton
# Import Module For AirFlow Schedular
# Import Module from SQL/Postges
# Write Function to extract data from selenium
# Do manual Deduplication so that same data should not insderted into Dataware house
# Do Trasnformation so that it can be store into structure format
# Load the structured data into dataware house 
# Create DAG with weekly schuduled and execute python code to automate website with proper webdriver it should be containarized within the task using PythonOperator from airFlow
# Load into dataware house in my case I will be using SqlServer or any free tier SQL databases 

# Most Important part---->
# Minimal depedency/module/library should be installed use Docker for the underlying dependencies to execeute
# Selenium needs a web browser and an executable web driver with ssame version it should be installed within the container
# perform Deduplication so that the data rededuncy can be achieved.
# Utilize Jira for project management tools and track with the other developer 
